# Flink + Kafka é›†æˆæŒ‡å—

## ğŸŒŠ Flink å®æ—¶æµå¤„ç†æ¶æ„

```
Kafka (æ•°æ®æº) â†’ Flink (æµå¤„ç†) â†’ MySQL/Redis (æ•°æ®å­˜å‚¨)
```

## ğŸ“‹ æœåŠ¡è®¿é—®ä¿¡æ¯

- **Flink Dashboard**: http://localhost:8083
- **Kafka Broker**: kafka:9092 (å®¹å™¨å†…) / localhost:9092 (å¤–éƒ¨)
- **MySQL**: mysql:3306 (å®¹å™¨å†…) / localhost:3306 (å¤–éƒ¨)  
- **Redis**: redis:6379 (å®¹å™¨å†…) / localhost:6379 (å¤–éƒ¨)

## ğŸ”§ Flink Job å¼€å‘ç¤ºä¾‹

### 1. Maven ä¾èµ–
```xml
<dependencies>
    <dependency>
        <groupId>org.apache.flink</groupId>
        <artifactId>flink-streaming-java</artifactId>
        <version>1.17.2</version>
    </dependency>
    <dependency>
        <groupId>org.apache.flink</groupId>
        <artifactId>flink-connector-kafka</artifactId>
        <version>1.17.2</version>
    </dependency>
    <dependency>
        <groupId>org.apache.flink</groupId>
        <artifactId>flink-connector-jdbc</artifactId>
        <version>3.1.0-1.17</version>
    </dependency>
</dependencies>
```

### 2. Kafka æ¶ˆè´¹è€…ç¤ºä¾‹
```java
// Kafka Source
FlinkKafkaConsumer<String> consumer = new FlinkKafkaConsumer<>(
    "user-events",  // topic
    new SimpleStringSchema(),
    properties);

DataStream<String> stream = env.addSource(consumer);
```

### 3. æ•°æ®å¤„ç†å’Œè¾“å‡º
```java
// å¤„ç†æ•°æ®å¹¶å†™å…¥ MySQL
stream.map(new MapFunction<String, UserEvent>() {
    @Override
    public UserEvent map(String value) throws Exception {
        // è§£æ JSON æˆ–å…¶ä»–æ ¼å¼
        return parseUserEvent(value);
    }
}).addSink(JdbcSink.sink(
    "INSERT INTO user_activities (user_id, activity_type, activity_data) VALUES (?, ?, ?)",
    (statement, event) -> {
        statement.setInt(1, event.getUserId());
        statement.setString(2, event.getActivityType());
        statement.setString(3, event.getActivityData());
    },
    JdbcExecutionOptions.builder()
        .withBatchSize(1000)
        .withBatchIntervalMs(200)
        .build(),
    new JdbcConnectionOptions.JdbcConnectionOptionsBuilder()
        .withUrl("jdbc:mysql://mysql:3306/projects")
        .withDriverName("com.mysql.cj.jdbc.Driver")
        .withUsername("appuser")
        .withPassword("apppassword")
        .build()));
```

## ğŸš€ ä½œä¸šæäº¤æµç¨‹

1. **æ‰“åŒ…ä½œä¸š**: `mvn clean package`
2. **ä¸Šä¼  JAR**: é€šè¿‡ Flink Web UI æˆ– REST API
3. **æäº¤ä½œä¸š**: é…ç½®å‚æ•°å¹¶å¯åŠ¨
4. **ç›‘æ§ä½œä¸š**: é€šè¿‡ Dashboard æŸ¥çœ‹çŠ¶æ€

## ğŸ“Š å¸¸ç”¨ Flink SQL

```sql
-- åˆ›å»º Kafka æºè¡¨
CREATE TABLE user_events (
    user_id INT,
    activity_type STRING,
    activity_data STRING,
    event_time TIMESTAMP(3) METADATA FROM 'timestamp'
) WITH (
    'connector' = 'kafka',
    'topic' = 'user-events',
    'properties.bootstrap.servers' = 'kafka:9092',
    'format' = 'json'
);

-- å®æ—¶èšåˆæŸ¥è¯¢
SELECT 
    user_id,
    COUNT(*) as activity_count,
    TUMBLE_END(event_time, INTERVAL '1' MINUTE) as window_end
FROM user_events
GROUP BY user_id, TUMBLE(event_time, INTERVAL '1' MINUTE);
```

## ğŸ¯ å…¸å‹åº”ç”¨åœºæ™¯

1. **å®æ—¶ETL**: Kafka â†’ Flink â†’ MySQL
2. **å®æ—¶èšåˆ**: è®¡ç®—ç”¨æˆ·æ´»è·ƒåº¦ã€è®¢å•ç»Ÿè®¡ç­‰
3. **å¼‚å¸¸æ£€æµ‹**: å®æ—¶ç›‘æ§å¼‚å¸¸æ¨¡å¼
4. **å®æ—¶æ¨è**: åŸºäºç”¨æˆ·è¡Œä¸ºçš„å®æ—¶æ¨è